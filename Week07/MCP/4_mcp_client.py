import sys
import asyncio
import streamlit as st
import json
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner # LLM ì—ì´ì „íŠ¸ ì‹¤í–‰
from agents.mcp import MCPServerStdio # MCP ì„œë²„ì™€ í„°ë¯¸ë„ í†µí•´ í†µì‹ 
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.envì—ì„œ API í‚¤ ë“±)
load_dotenv()

# Streamlit UIë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„, LLM + MCP Toolì„ ì¡°í•©í•´ ì‘ë‹µì„ ìƒì„±í•˜ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ì—ì´ì „íŠ¸ í´ë¼ì´ì–¸íŠ¸

# Windows í™˜ê²½ì—ì„œ asyncio ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ ì„¤ì •
if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    

# ----------------------------
#  ğŸ§  MCP ì„œë²„ ì—°ê²° ì„¤ì • í•¨ìˆ˜
# ----------------------------
async def setup_mcp_servers():
    servers = []
    
    # mcp.json íŒŒì¼ì—ì„œ ì„¤ì •ë‚´ìš© ì½ê¸°
    with open('mcp.json', 'r') as f:
        config = json.load(f)
    
    # # ì„œë²„ ì´ë¦„ê³¼ ëª…ë ¹ì–´ë¡œ MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰ ë° ì—°ê²°, MCP ì„œë²„ë“¤ì„ ìˆœíšŒ
    # ê° MCP ì„œë²„ë¥¼ MCPServerStdio ì¸ìŠ¤í„´ìŠ¤ë¡œ ê°ì‹¸ê³  ì—°ê²°
    # ì—¬ëŸ¬ ì„œë²„ë¥¼ ë™ì‹œì— ë“±ë¡í•  ìˆ˜ë„ ìˆìŒ
    for server_name, server_config in config.get('mcpServers', {}).items():
        mcp_server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", [])
            },
            cache_tools_list=True
        )
        await mcp_server.connect()
        servers.append(mcp_server)

    return servers

# --------------------------------------
#  ğŸ¤– LLMê¸°ë°˜ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”, ì„¤ì •
# --------------------------------------
async def setup_agent():
    # ì„œë²„ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±
    mcp_servers = await setup_mcp_servers()
    
    # GPT ëª¨ë¸ + MCP ì„œë²„ ë„êµ¬ë¥¼ ì—°ê²°í•œ ì—ì´ì „íŠ¸ ìƒì„±
    agent = Agent(
        name="Assistant",
        instructions="ë„ˆëŠ” ìœ íŠœë¸Œ ì»¨í…ì¸  ë¶„ì„ì„ ë„ì™€ì£¼ëŠ” ì—ì´ì „íŠ¸ì•¼",
        model="gpt-4o-mini",
        mcp_servers=mcp_servers    # LLM + MCP íˆ´ì„ ëª¨ë‘ ì‚¬ìš©
    )
    return agent,mcp_servers

# --------------------------------------------------
# ğŸ“¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ + ìŠ¤íŠ¸ë¦¬ë° : ì‘ë‹µë©”ì‹œì§€ ì²˜ë¦¬
# --------------------------------------------------
async def process_user_message():
    agent,mcp_servers = await setup_agent()
    messages = st.session_state.chat_history # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    
    # ë©”ì‹œì§€ë¥¼ GPTì— ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì „ë‹¬
    result = Runner.run_streamed(agent, input=messages) 

    response_text = ""
    placeholder = st.empty()
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥ ì²˜ë¦¬
    async for event in result.stream_events(): # ìŠ¤íŠ¸ë¦¬ë° í† í° ì¶œë ¥ (result.stream_events())
        # LLM ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë°
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            response_text += event.data.delta or ""
            with placeholder.container():
                with st.chat_message("assistant"):
                    st.markdown(response_text)


        # MCP ë„êµ¬ ì´ë²¤íŠ¸ì™€ ë©”ì‹œì§€ ì™„ë£Œ ì²˜ë¦¬
        elif event.type == "run_item_stream_event":
            item = event.item

            if item.type == "tool_call_item":
                tool_name = item.raw_item.name
                st.toast(f"ğŸ›  ë„êµ¬ í™œìš©: `{tool_name}`")
                
    # ì‘ë‹µì„ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.chat_history.append({
        "role": "assistant",
        "content": response_text
    })
    
    # ëª…ì‹œì  ì¢…ë£Œ (streamlitì—ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
    for server in mcp_servers:
        await server.__aexit__(None, None, None)

# ----------------------------
# Streamlit UI ë©”ì¸
# ----------------------------
def main():
    st.set_page_config(page_title="ìœ íŠœë¸Œ ì—ì´ì „íŠ¸", page_icon="ğŸ¥")
    
    # ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    st.title("ğŸ¥ ìœ íŠœë¸Œ ì»¨í…ì¸  ì—ì´ì „íŠ¸")
    st.caption("ìœ íŠœë¸Œ ì»¨í…ì¸  ì œì‘, ì•„ì´ë””ì–´, íŠ¸ë Œë“œì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!")

    for m in st.session_state.chat_history:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("ëŒ€í™”ë¥¼ í•´ì£¼ì„¸ìš”")
    if user_input:
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # ë¹„ë™ê¸° ì‘ë‹µ ì²˜ë¦¬
        asyncio.run(process_user_message())
        
# ----------------------------
# ì•± ì‹¤í–‰
# ----------------------------
if __name__ == "__main__":
    main()
