{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/2025_Spring_Capstone-Design/blob/main/Week12/LLM_Transformer_Pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa4u8Q2Cg1zd"
      },
      "source": [
        "___\n",
        "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
        "___\n",
        "<center><em>Content Copyright by HongLab, Inc.</em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCsrV0MLg1zh"
      },
      "source": [
        "## 대형언어모델(LLM) 바닥부터 만들기\n",
        "\n",
        "[유튜브 강의 영상 링크](https://youtu.be/osv2csoHVAo)\n",
        "\n",
        "[홍정모 연구소 디스코드 링크](https://discord.com/invite/kgR9xJkbsV)\n",
        "\n",
        "[홍정모 연구소 홈페이지 링크](https://www.honglab.ai/)\n",
        "\n",
        "#### 참고 자료\n",
        "- [Andrej Karpathy 유튜브](https://www.youtube.com/andrejkarpathy)\n",
        "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
        "- [Om-Alve/smolGPT 깃헙](https://github.com/Om-Alve/smolGPT)\n",
        "- 트랜스포머 논문 - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "- OpenAI GPT2 논문 - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_atO1cqkg1zk"
      },
      "source": [
        "### 안내사항\n",
        "\n",
        "- LLM의 핵심 개념을 개인 PC에서도 간단하게 실습하면서 공부\n",
        "\n",
        "- Pytorch 2.6, CUDA 12.6 에서 작동을 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEGXduxg1zm"
      },
      "source": [
        "## 전체 과정 요약\n",
        "\n",
        "- LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요,\n",
        "- LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다.\n",
        "- 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
        "\n",
        "## LLM을 만들 때는\n",
        "\n",
        "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에\n",
        "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응시키는 것이 기본\n",
        "3. 데이터베이스(+인터넷) 검색 기능을 추가(지식의 범위와 정확성을 Up)\n",
        "4. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도 내부적으로 질의를 반복하여 더 좋은 결론을 도출(Reasoning)\n",
        "\n",
        "## LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행\n",
        "- 훈련 과정의 큰 틀은 일반적인 머신러닝 절차\n",
        "\n",
        "1. 훈련 데이터 준비\n",
        "1. 데이터 로더 정의\n",
        "1. 모델 정의\n",
        "1. 훈련\n",
        "1. 결과 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrRyAH7Ug1zo"
      },
      "source": [
        "### 훈련 데이터 준비\n",
        "\n",
        "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
        "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
        "\n",
        "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
        "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
        "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 02 Harry Potter and the Chamber of Secrets.txt 파일을 읽기\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Replace with the actual path to your zip file\n",
        "zip_file_path = '/content/archive (2).zip'\n",
        "extracted_text_file_path = '/content/02 Harry Potter and the Chamber of Secrets.txt'  # Path to the extracted text file\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Find the specific file within the zip archive\n",
        "        for file_info in zip_ref.infolist():\n",
        "            print(\"Files in the zip archive:\")\n",
        "            print(file_info.filename)\n",
        "            if file_info.filename == '02 Harry Potter and the Chamber of Secrets.txt':\n",
        "                # Extract the file\n",
        "                zip_ref.extract(file_info, '/content/')\n",
        "                print(f\"Successfully extracted: {file_info.filename}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Error: '02 Harry Potter and the Chamber of Secrets.txt' not found in the zip archive\")\n",
        "\n",
        "    # Read the extracted text file\n",
        "    with open(extracted_text_file_path, 'r', encoding='utf-8') as file:\n",
        "        file_content = file.read()\n",
        "        # Now you can process the file content (file_content)\n",
        "        print(f\"First 200 characters of the file:\\n{file_content[:200]}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at '{zip_file_path}'\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: Invalid zip file '{zip_file_path}'\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7mfMj9B_-y8",
        "outputId": "0ce6d8f8-b6ab-4a78-d889-f60b31c5a4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the zip archive:\n",
            "01 Harry Potter and the Sorcerers Stone.txt\n",
            "Files in the zip archive:\n",
            "02 Harry Potter and the Chamber of Secrets.txt\n",
            "Successfully extracted: 02 Harry Potter and the Chamber of Secrets.txt\n",
            "First 200 characters of the file:\n",
            "Not for the first time, an argument had broken out over breakfast at number four, Privet Drive. Mr. Vernon Dursley had been woken in the early hours of the morning by a loud, hooting noise from his ne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Files in the zip archive:\")\n",
        "for file_info in zip_ref.infolist():\n",
        "    print(file_info.filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NracI7ZhFcGy",
        "outputId": "9198e720-b0d1-448a-ac2b-d9026d8e7813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the zip archive:\n",
            "01 Harry Potter and the Sorcerers Stone.txt\n",
            "02 Harry Potter and the Chamber of Secrets.txt\n",
            "03 Harry Potter and the Prisoner of Azkaban.txt\n",
            "04 Harry Potter and the Goblet of Fire.txt\n",
            "05 Harry Potter and the Order of the Phoenix.txt\n",
            "06 Harry Potter and the Half-Blood Prince.txt\n",
            "07 Harry Potter and the Deathly Hallows.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7tWj9jig1zp",
        "outputId": "7d320f83-1536-4ea0-ad65-85c2dc22269d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
        "\n",
        "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
        "\n",
        "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
        "\n",
        "for filename in filenames_list:\n",
        "    clean_text(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys0x9OBcg1zv"
      },
      "source": [
        "#### 토큰화\n",
        "\n",
        "UTF-8 BPE(Bype Pair Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvtSjCpxiT0p",
        "outputId": "a61eafc5-8231-4f83-b339-3c6ff5963a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLC3THr-g1zx",
        "outputId": "c709dd21-71dc-4557-ec56-bbb8adcbd07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "글자수: 26 토큰수 6\n",
            "[18308, 14179, 373, 257, 18731, 13]\n",
            "Harry Potter was a wizard.\n",
            "18308\t -> Harry\n",
            "14179\t ->  Potter\n",
            "373\t ->  was\n",
            "257\t ->  a\n",
            "18731\t ->  wizard\n",
            "13\t -> .\n"
          ]
        }
      ],
      "source": [
        "import tiktoken # pip install tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Harry Potter was a wizard.\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))\n",
        "for t in tokens:\n",
        "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozW5W27Jg1zz"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer # pip install transformers\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
        "\n",
        "# print(\"Vocab size :\", len(tokenizer))\n",
        "\n",
        "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
        "\n",
        "# tokens = tokenizer.encode(text)\n",
        "\n",
        "# print(len(text), len(tokens))\n",
        "# print(tokens)\n",
        "# print(tokenizer.decode(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Sx12A1g1z2",
        "outputId": "d798647a-f747-4330-d0d7-ef8282b10a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H -> [39] -> H\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "r -> [81] -> r\n",
            "y -> [88] -> y\n",
            "  -> [220] ->  \n",
            "P -> [47] -> P\n",
            "o -> [78] -> o\n",
            "t -> [83] -> t\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "a -> [64] -> a\n",
            "s -> [82] -> s\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "i -> [72] -> i\n",
            "z -> [89] -> z\n",
            "a -> [64] -> a\n",
            "r -> [81] -> r\n",
            "d -> [67] -> d\n",
            ". -> [13] -> .\n"
          ]
        }
      ],
      "source": [
        "for char in text:\n",
        "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
        "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
        "    print(f\"{char} -> {token_ids} -> {decoded}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EpqZrNwg1z3"
      },
      "source": [
        "#### 데이터로더(DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6e64h_yg1z4",
        "outputId": "dbe710f7-c7b8-42f5-fb7e-51880daace7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of tokens in txt: 2661\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        print(\"# of tokens in txt:\", len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "# with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "#     txt = file.read()\n",
        "\n",
        "\n",
        "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "    txt = file.read()\n",
        "\n",
        "txt = txt[:10000]\n",
        "\n",
        "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
        "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yD_Iciwg1z6",
        "outputId": "25b54490-0b94-4117-fad1-81e1b9288bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " what wizards called Muggles (not a drop of magical blood in their veins), and as far as they were concerned, having a wizard in the family was\n",
            " wizards called Muggles (not a drop of magical blood in their veins), and as far as they were concerned, having a wizard in the family was a\n"
          ]
        }
      ],
      "source": [
        "dataiter = iter(train_loader)\n",
        "\n",
        "x, y = next(dataiter)\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_jdTj7qg1z7"
      },
      "source": [
        "#### 뉴럴네트워크 모델 정의\n",
        "\n",
        "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n",
        "\n",
        "### [모델 정의 (GPT 구조)]\n",
        "- Embedding Layer (Token + Position)\n",
        "- TransformerBlock (MultiHeadAttention + FFN)\n",
        "- Linear 출력층 → 단어 예측\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EINNmnOg1z8"
      },
      "outputs": [],
      "source": [
        "# 모델을 정의할 때 사용하는 상수들\n",
        "\n",
        "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
        "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
        "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
        "EMB_DIM = 768  # Embedding dimension\n",
        "NUM_HEADS = 12  # Number of attention heads\n",
        "NUM_LAYERS = 12  # Number of layers\n",
        "DROP_RATE = 0.1  # Dropout rate\n",
        "QKV_BIAS = False  # Query-key-value bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLIfuowog1z8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // NUM_HEADS\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(DROP_RATE)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=EMB_DIM,\n",
        "            d_out=EMB_DIM)\n",
        "\n",
        "        self.ff = FeedForward()\n",
        "        self.norm1 = LayerNorm(EMB_DIM)\n",
        "        self.norm2 = LayerNorm(EMB_DIM)\n",
        "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
        "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
        "\n",
        "        self.final_norm = LayerNorm(EMB_DIM)\n",
        "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCUwjiu2g1z-"
      },
      "source": [
        "#### 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpX26pong1z_",
        "outputId": "44286f9d-ff7e-404b-e974-9846d7ef7f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = \"cpu\"\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3nuFZ8g10A",
        "outputId": "6a1354cd-1a32-4b01-bc6e-233b63581876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens seen: 4096\n",
            "Epoch: 1, Loss: 8.836424827575684\n",
            "Epoch: 2, Loss: 6.159327507019043\n",
            "Epoch: 3, Loss: 4.637236595153809\n",
            "Epoch: 4, Loss: 3.628055953979492\n",
            "Epoch: 5, Loss: 2.844139003753662\n"
          ]
        }
      ],
      "source": [
        "tokens_seen, global_step = 0, -1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward() # Calculate loss gradients\n",
        "        optimizer.step() # Update model weights using loss gradients\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % 1000 == 0:\n",
        "            print(f\"Tokens seen: {tokens_seen}\")\n",
        "        # Optional evaluation step\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
        "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
        "\n",
        "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다.\n",
        "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9gWE6YLdg10B",
        "outputId": "487fb817-073f-409c-a906-8721eabf101e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ZVuouUg10B"
      },
      "source": [
        "#### 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjJ3ar_Vg10C",
        "outputId": "162e80c1-0b30-4c46-8670-86583d7d9d32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(128, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
        "model.load_state_dict(torch.load(\"model_005.pth\", map_location=device, weights_only=True))\n",
        "model.eval() # dropout을 사용하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r30mK_cbg10C",
        "outputId": "7e7bd92f-4eea-4587-d737-acd5a4683623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.03\t 257\t  a\n",
            "6.59\t 286\t  of\n",
            "5.45\t 11\t ,\n",
            "5.25\t 1744\t  possible\n",
            "5.09\t 10153\t  scar\n",
            "4.75\t 329\t  for\n",
            "4.69\t 351\t  with\n",
            "4.62\t 345\t  you\n",
            "4.61\t 588\t  like\n",
            "4.59\t 262\t  the\n",
            " a\n"
          ]
        }
      ],
      "source": [
        "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
        "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(idx)\n",
        "\n",
        "logits = logits[:, -1, :]\n",
        "\n",
        "# 가장 확률이 높은 단어 10개 출력\n",
        "top_logits, top_indices = torch.topk(logits, 10)\n",
        "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
        "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
        "\n",
        "# 가장 확률이 높은 단어 출력\n",
        "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
        "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG6yCxKyg10D"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [llm-temperature](https://www.hopsworks.ai/dictionary/llm-temperature)\n",
        "\n",
        "<img src='https://cdn.prod.website-files.com/618399cd49d125734c8dec95/6639e35ce91c16b3b9564b2f_mxaIPcROZcBFYta1I0nzWjlGTgs-LxzUOE3p6Kbvf9qPpZzBh5AAZG7ciRtgVquhLTtrM8ToJdNd-ubXvuz8tRfrqBwSozWHCj457pm378buxz2-XrMfWzfSv3b793QP61kLxRKT299WP1gbas_E118.png'>"
      ],
      "metadata": {
        "id": "iwdPdDjLqM6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhNr_L1Og10E",
        "outputId": "485e5d01-8417-4aef-e444-98fd87a55366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start context: I am\n",
            "0 : I am, and, and Hermione with his wand, and pretending I” he had come home. “And you,” “I’s” “I” “I” said Uncle Vernon.”\n",
            "1 : I am, and pretending I” “I’t told the lounge,’ll have to the Dursleys” he had come home.” Harry” he was so,” said Uncle Vernon,” �\n",
            "2 : I am, you, and hugged to the news at Hogwarts had been on the Dursleys’t even than, and pretending I’ll be in my. He had been treating him any moment, and his wand, Petunia. “\n",
            "3 : I am, and his wife, and I’ll have the Dursleys’t know,” “I” he had been talking of his wand,” Harry. “I” said Uncle Vernon. “\n",
            "4 : I am, and he was it. “And you,’t know, you” “I” said Aunt Petunia. “I” “I” “You to be in my room. “\n",
            "5 : I am,’m not there, Dudley,” “I” “I” said Aunt Petunia,” “I” “I’ll be in my,” said Uncle Vernon,�\n",
            "6 : I am, and pretending I’t know,” “I” said Uncle Vernon,’t you” “I” “I” “I’m not there,” said Harry.\n",
            "7 : I am, and I” said Aunt Petunia, “I” “I’m not there,” “I” “I” he had come out. “We to the table.”\n",
            "8 : I am. “I” said Harry’s room,’t a wizarding world. “Perfect…’m not there, and his feet,” he was it’s sister and his” “\n",
            "9 : I am,” said Uncle Vernon. “I’ll be in the Dursleys’m not there,” he had been locked in the frying pan. “I’s room,” he had been destroyed\n"
          ]
        }
      ],
      "source": [
        "start_context = input(\"Start context: \")\n",
        "\n",
        "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
        "idx = tokenizer.encode(start_context)\n",
        "idx = torch.tensor(idx).unsqueeze(0)\n",
        "\n",
        "context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=idx.to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size= context_size,\n",
        "        top_k=50,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
        "\n",
        "    print(i, \":\", out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drTv4FNUg10F"
      },
      "source": [
        "#### 보충\n",
        "\n",
        "- 여기서 소개해드린 LLM은 한 단어씩 만들어 가는 **자동회귀(autoregressive)** LLM 이라고 합니다. (자가회귀로 번역하기도 합니다.)\n",
        "- 최근에는 **디퓨전(Diffusion)** LLM 기술도 나오기 시작했습니다. 한번에 한 단어씩이 아니라 전체를 생성합니다. ([참고1](https://x.com/karpathy/status/1894923254864978091), [참고2](https://x.com/omarsar0/status/1891568386494300252))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}